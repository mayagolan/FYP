{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iCGVJW3cjnD"
   },
   "source": [
    "# Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Vq85CYTFcjnO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/maya/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output_png {\n",
       "    display: table-cell;\n",
       "    text-align: center;\n",
       "    vertical-align: middle;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np  \n",
    "from   datetime import datetime\n",
    "import glob\n",
    "import pysentiment2 as ps\n",
    "import nltk\n",
    "from   nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from   IPython.core.display import HTML\n",
    "from   os import path\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "lm    = ps.LM()\n",
    "hiv4  = ps.HIV4()\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "finbert_tokenizer  = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "finbert_model      = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
    "finbert_classifier = pipeline(\"sentiment-analysis\", model = finbert_model, tokenizer = finbert_tokenizer)\n",
    "\n",
    "HTML(\"\"\"\n",
    "<style>\n",
    ".output_png {\n",
    "    display: table-cell;\n",
    "    text-align: center;\n",
    "    vertical-align: middle;\n",
    "}\n",
    "</style>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vAQtm9scjnR"
   },
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentimentAnalysisLMD(text):\n",
    "    tokens = lm.tokenize(text) #tokenize the text into relevant words in the LM dict\n",
    "    score = lm.get_score(tokens) #score dict seperates into: NEG, POS, POLARITY, SUBJECTIVITY\n",
    "    return score\n",
    "\n",
    "def sentimentAnalysisHIV4(text):\n",
    "    tokens = hiv4.tokenize(text)\n",
    "    score = hiv4.get_score(tokens)\n",
    "    return score\n",
    "\n",
    "def sentimentAnalysisVader(df):\n",
    "  df_vader = pd.DataFrame(df, columns=['Date', 'Text'])\n",
    "  scores = df_vader['Text'].apply(vader.polarity_scores).tolist()\n",
    "  scores_vader = pd.DataFrame(scores).add_prefix(\"vader_\")\n",
    "  df_vader = df_vader.join(scores_vader, rsuffix='_right')\n",
    "  return df_vader['vader_compound']\n",
    "  \n",
    "def sentimentAnalysisFinBert(df):\n",
    "  df_finbert = pd.DataFrame(df, columns=['Date', 'Text'])\n",
    "  score = []\n",
    "  for i in range(len(df_finbert)):\n",
    "    classified = finbert_classifier(df_finbert['Text'][i], truncation=True)[0]\n",
    "    if classified['label'] == \"negative\":\n",
    "        score.append(classified['score']*(-1))\n",
    "    elif classified['label'] == \"positive\":\n",
    "        score.append(classified['score'])\n",
    "    else:\n",
    "        score.append(0)\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GHoaltU1cjnR",
    "outputId": "3a136267-731e-4cf5-ee1f-8d2c316c07d9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ameren Corporation.csv\n",
      "American Assets Trust.csv\n",
      "Aptiv Plc.csv\n",
      "Archer Daniels Midland.csv\n",
      "Barry Callebaut AG R.csv\n",
      "Boral Limited.csv\n",
      "Danone SA.csv\n",
      "Deutsche Telekom AG .csv\n",
      "nVent Electric Plc.csv\n"
     ]
    }
   ],
   "source": [
    "lst_companies = [] \n",
    "lst_files = [] \n",
    "\n",
    "Path = \"*.csv\"\n",
    "count = 0\n",
    "\n",
    "for fname in glob.glob(Path):\n",
    "    lst_files.append(fname)\n",
    "\n",
    "lst_files = sorted(lst_files)\n",
    "\n",
    "for file in lst_files:\n",
    "    if not path.isfile(r'/Users/maya/OneDrive - Imperial College London/EE4/FYP/Final-Year-Project-main/TMF Sentiment/{0}'.format(file)):\n",
    "        print(file)\n",
    "        df = pd.read_csv(file)\n",
    "        df['Text'] = df['Text'].astype(str)\n",
    "        df = df.drop_duplicates(['Date','Headline'], keep='last')\n",
    "        df = df.drop(['Unnamed: 0', 'Headline'], axis = 1)\n",
    "        df['Date'] = pd.to_datetime(df['Date'], utc=True).dt.date \n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        if df.shape[0] != 0:\n",
    "            #LMD + HIV4\n",
    "            df_LMD_HIV4 = pd.DataFrame(df, columns=['Date', 'Text'])\n",
    "            df_LMD_HIV4[\"scoreLMD\"] = df_LMD_HIV4[\"Text\"].apply(sentimentAnalysisLMD)\n",
    "            df_LMD_HIV4[\"scoreHIV4\"] = df_LMD_HIV4[\"Text\"].apply(sentimentAnalysisHIV4)\n",
    "            df_LMD_HIV4 = pd.concat([df_LMD_HIV4.drop([\"scoreLMD\"], axis=1), df_LMD_HIV4[\"scoreLMD\"].apply(pd.Series).add_prefix(\"LMD_\")], axis=1)\n",
    "            df_LMD_HIV4 = pd.concat([df_LMD_HIV4.drop([\"scoreHIV4\"], axis=1), df_LMD_HIV4[\"scoreHIV4\"].apply(pd.Series).add_prefix(\"HIV4_\")], axis=1)\n",
    "            df[['LMD_Polarity', 'HIV4_Polarity']] = df_LMD_HIV4[['LMD_Polarity', 'HIV4_Polarity']]\n",
    "\n",
    "            #VADER\n",
    "            df['Vader_Polarity'] = sentimentAnalysisVader(df)\n",
    "\n",
    "            #FINBERT\n",
    "            df['FinBert_Polarity'] = sentimentAnalysisFinBert(df)\n",
    "\n",
    "            # Find the average Polarity for each Dictionary, per given date \n",
    "            df = df.groupby('Date').mean().reset_index()\n",
    "            df = df.sort_values(by = ['Date'], ascending = True)\n",
    "            idx = pd.date_range('2015-02-03', '2021-12-31')\n",
    "            df = df.set_index(['Date']).reindex(idx, fill_value=np.nan).rename_axis('Date').reset_index()\n",
    "\n",
    "            company_name = file[0:len(file)-4].strip()\n",
    "            lst_companies.append(company_name)\n",
    "            df['Company'] = company_name\n",
    "            df= df[['Date', 'Company', 'LMD_Polarity', 'HIV4_Polarity', 'Vader_Polarity', 'FinBert_Polarity']]\n",
    "\n",
    "            count = count + 1\n",
    "#             print(company_name)\n",
    "            print(count)\n",
    "            df.to_csv(r'/Users/maya/OneDrive - Imperial College London/EE4/FYP/Final-Year-Project-main/TMF Sentiment/{0}.csv'.format(company_name))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sentiment Analysis - Reuters (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
