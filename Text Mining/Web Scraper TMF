{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeJsk2seVXbx",
        "outputId": "11b6484b-dce1-47b5-f8bb-7c5033807fe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.1.0-py3-none-any.whl (958 kB)\n",
            "\u001b[K     |████████████████████████████████| 958 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting trio~=0.17\n",
            "  Downloading trio-0.19.0-py3-none-any.whl (356 kB)\n",
            "\u001b[K     |████████████████████████████████| 356 kB 51.8 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting urllib3[secure]~=1.26\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 49.1 MB/s \n",
            "\u001b[?25hCollecting outcome\n",
            "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.0.0-py3-none-any.whl (24 kB)\n",
            "Collecting cryptography>=1.3.4\n",
            "  Downloading cryptography-36.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.6 MB 40.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure]~=1.26->selenium) (2021.10.8)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-21.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure]~=1.26->selenium) (2.21)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from pyOpenSSL>=0.14->urllib3[secure]~=1.26->selenium) (1.15.0)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.8 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-36.0.1 h11-0.12.0 outcome-1.1.0 pyOpenSSL-21.0.0 selenium-4.1.0 sniffio-1.2.0 trio-0.19.0 trio-websocket-0.9.2 urllib3-1.26.8 wsproto-1.0.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [76.0 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [725 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,459 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,498 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [867 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,823 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,952 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [934 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,240 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [771 kB]\n",
            "Get:26 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 14.7 MB in 4s (3,701 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 58 not upgraded.\n",
            "Need to get 95.3 MB of archives.\n",
            "After this operation, 327 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 97.0.4692.71-0ubuntu0.18.04.1 [1,142 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 97.0.4692.71-0ubuntu0.18.04.1 [84.7 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 97.0.4692.71-0ubuntu0.18.04.1 [4,370 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 97.0.4692.71-0ubuntu0.18.04.1 [5,055 kB]\n",
            "Fetched 95.3 MB in 4s (22.9 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155229 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_97.0.4692.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_97.0.4692.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_97.0.4692.71-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_97.0.4692.71-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (97.0.4692.71-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9HVkUcXVoxD"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd\n",
        "import os\n",
        "import re \n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import time\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.by import By\n",
        "import urllib3\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "# import requests \n",
        "from urllib import request\n",
        "from google.colab import files\n",
        "import sys\n",
        "from selenium import webdriver"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFbLM9NqVsTI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cffec61-6669-4fe4-ec8e-4dfe821196bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')\n",
        "df=pd.read_csv('gdrive/My Drive/Colab Notebooks/FYP/TMF List.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-YFduQBdqDj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "outputId": "1f6f6dfe-292e-48ce-a47b-50e2b66ae2e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b4a815ab-d597-45b5-a939-cdaa344e5bf0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>descrption</th>\n",
              "      <th>Unnamed: 1</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>Thermo Fisher Scientific Inc</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/thermo-fisher-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>Thomson Reuters Corp.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/thomson-reuter...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>Transocean Inc.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/rig/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>Trimble Inc</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nasdaq/trimble/trmb/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>Uber Technologies</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/uber/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>United States Steel Corporation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/x/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>Valmont Industries Inc.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/vmi/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>Ventas</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/vtr/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>Verizon Communications Inc.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/vz/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>Walmart Inc.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/wmt/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>Walt Disney</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/dis/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>Waste Management Inc.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/wm/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>Wec Energy Group Incorporation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/wec/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>Weibo Corporation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nasdaq/wb/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>WELLTOWER INC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/welltower/well/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>Westinghouse Air Brake Technologies Corporation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/wab/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>Westlake Chemical Corporation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/wlk/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>WestRock Company</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/wrk/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>Weyerhaeuser Company</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/wy/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>Whirlpool Corporation</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/whr/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>Williams Companies</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/wmb/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>Xcel Energy Inc</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/xel/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>Xilinx Inc.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nasdaq/xlnx/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>Xylem Inc.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/xyl/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>474</th>\n",
              "      <td>Yum! Brands</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/yum/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>Zimmer Biomet Holdings  Inc</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/zbh/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>Zoetis Inc.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://www.fool.com/quote/nyse/zts</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4a815ab-d597-45b5-a939-cdaa344e5bf0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b4a815ab-d597-45b5-a939-cdaa344e5bf0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b4a815ab-d597-45b5-a939-cdaa344e5bf0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                          descrption  ...                                                url\n",
              "450                     Thermo Fisher Scientific Inc  ...  https://www.fool.com/quote/nyse/thermo-fisher-...\n",
              "451                            Thomson Reuters Corp.  ...  https://www.fool.com/quote/nyse/thomson-reuter...\n",
              "452                                  Transocean Inc.  ...               https://www.fool.com/quote/nyse/rig/\n",
              "453                                      Trimble Inc  ...    https://www.fool.com/quote/nasdaq/trimble/trmb/\n",
              "454                               Uber Technologies   ...              https://www.fool.com/quote/nyse/uber/\n",
              "455                  United States Steel Corporation  ...                 https://www.fool.com/quote/nyse/x/\n",
              "456                          Valmont Industries Inc.  ...               https://www.fool.com/quote/nyse/vmi/\n",
              "457                                          Ventas   ...               https://www.fool.com/quote/nyse/vtr/\n",
              "458                      Verizon Communications Inc.  ...                https://www.fool.com/quote/nyse/vz/\n",
              "459                                    Walmart Inc.   ...               https://www.fool.com/quote/nyse/wmt/\n",
              "460                                     Walt Disney   ...               https://www.fool.com/quote/nyse/dis/\n",
              "461                            Waste Management Inc.  ...                https://www.fool.com/quote/nyse/wm/\n",
              "462                   Wec Energy Group Incorporation  ...               https://www.fool.com/quote/nyse/wec/\n",
              "463                                Weibo Corporation  ...              https://www.fool.com/quote/nasdaq/wb/\n",
              "464                                    WELLTOWER INC  ...    https://www.fool.com/quote/nyse/welltower/well/\n",
              "465  Westinghouse Air Brake Technologies Corporation  ...               https://www.fool.com/quote/nyse/wab/\n",
              "466                    Westlake Chemical Corporation  ...               https://www.fool.com/quote/nyse/wlk/\n",
              "467                                WestRock Company   ...               https://www.fool.com/quote/nyse/wrk/\n",
              "468                             Weyerhaeuser Company  ...                https://www.fool.com/quote/nyse/wy/\n",
              "469                            Whirlpool Corporation  ...               https://www.fool.com/quote/nyse/whr/\n",
              "470                              Williams Companies   ...               https://www.fool.com/quote/nyse/wmb/\n",
              "471                                  Xcel Energy Inc  ...               https://www.fool.com/quote/nyse/xel/\n",
              "472                                      Xilinx Inc.  ...            https://www.fool.com/quote/nasdaq/xlnx/\n",
              "473                                       Xylem Inc.  ...               https://www.fool.com/quote/nyse/xyl/\n",
              "474                                     Yum! Brands   ...               https://www.fool.com/quote/nyse/yum/\n",
              "475                      Zimmer Biomet Holdings  Inc  ...               https://www.fool.com/quote/nyse/zbh/\n",
              "476                                      Zoetis Inc.  ...                https://www.fool.com/quote/nyse/zts\n",
              "\n",
              "[27 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.iloc[450:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8za9ajWnVwaj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "b7d019ad-936b-4266-ca34-ff4cbb97df01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Home Depot Inc.\n",
            "https://www.fool.com/quote/nyse/home-depot/hd/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0401365d-c793-49d5-86a7-9e65c77c0e6e\", \"The Home Depot Inc..csv\", 6841694)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Interpublic Group of Companies Inc\n",
            "https://www.fool.com/quote/nyse/the-interpublic-group-of-companies/ipg/\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f6c23de6-eaeb-4b5b-b948-b2bc0a0febd8\", \"The Interpublic Group of Companies Inc.csv\", 201757)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "for index, row in df.iloc[458:460].iterrows():\n",
        "    sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "    chrome_options = webdriver.ChromeOptions()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome('chromedriver',options=chrome_options)\n",
        "    company_name = row['description']\n",
        "    print(company_name)\n",
        "    url = row['url']\n",
        "    print(url)\n",
        "\n",
        "    if not pd.isna(url):\n",
        "      driver.get(url)\n",
        "      wait = WebDriverWait(driver, 20)\n",
        "      # XPATHS COOKIE MARKETMOVES = [ ' //*[@id=\"modal−form\"]/fieldset/ul[1]/li[1]/label/input ' , ' //*[@id=\"modal−form\"]/fieldset/ul[2]/li[1]/label/input ' , ' //*[@id=\"gdpr−submit−button\"] ' ]\n",
        "\n",
        "      # for i in range(0, 3):\n",
        "      #   button = wait.until(EC.element to be clickable ((By.XPATH , XPATHS COOKIE MARKETMOVES[i])))\n",
        "      #   driver.execute script(\"arguments[0].click()\", button)\n",
        "      #   time.sleep(3)\n",
        "      \n",
        "      try:\n",
        "        while(driver.find_element_by_xpath('//*[@id=\"load-more\"]').is_displayed()):\n",
        "          element = driver.find_element_by_xpath('//*[@id=\"load-more\"]')\n",
        "          driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
        "          time.sleep(3)\n",
        "          button = wait.until(EC.element_to_be_clickable((By.XPATH, '//*[@id=\"load-more\"]')))\n",
        "          driver.execute_script(\"arguments[0].click()\", button)\n",
        "          time.sleep(3)\n",
        "\n",
        "      except:\n",
        "        pass \n",
        "\n",
        "      html = driver.page_source\n",
        "      f = open('{0}.html'.format(company_name), 'w')\n",
        "      f.write(html.encode('utf-8').decode('ascii', 'ignore'))\n",
        "      f.close()\n",
        "      driver.close()\n",
        "      http=urllib3.PoolManager()\n",
        "      data = open('{0}.html'.format(company_name),'r')\n",
        "      \n",
        "      soup = BeautifulSoup(data, 'html.parser')\n",
        "      data1 = soup.find('div', attrs = {'class': 'quote-page-article-listing'})\n",
        "      links = []\n",
        "      for link in data1.find_all('a'): \n",
        "        links.append(link.get('href'))\n",
        "      \n",
        "      links = list(dict.fromkeys(links))\n",
        "      newlinks = [x for x in links if not x.startswith('https')]\n",
        "      newlinks = [x for x in newlinks if not x.startswith('/earnings')]\n",
        "\n",
        "      locals()[\"df\"+str(company_name)] = pd.DataFrame(columns = ['Author', 'Date', 'Headline', 'Text'])\n",
        "\n",
        "\n",
        "      for link in newlinks: \n",
        "        try:\n",
        "          url = \"https://www.fool.com\" + link \n",
        "          html = request.urlopen(url).read().decode('utf8')\n",
        "          soup = BeautifulSoup(html, 'html.parser')\n",
        "          head = soup.find('section', attrs = {'class': 'usmf-new article-header'})\n",
        "          headline = head.find('h1').string\n",
        "          sub_headline = head.find('h2').string\n",
        "          author = soup.find('div', attrs = {'class': 'author-name'}).find('a').string\n",
        "          dates = soup.find_all('div', attrs = {'class': 'publication-date'})\n",
        "          dates_list = []\n",
        "          for date in dates: \n",
        "              dates_list.append(date.contents[2].strip())\n",
        "\n",
        "          for i in dates_list: \n",
        "              if i.startswith('Published') and len(dates_list) > 1: \n",
        "                  date_final = i\n",
        "              else: \n",
        "                  date_final = i \n",
        "\n",
        "          text = soup.find('span', attrs = {'class': 'article-content'})\n",
        "          paragraphs = text.find_all('p')\n",
        "          text_final = \"\"\n",
        "          for paragraph in paragraphs:\n",
        "              text_final = text_final + paragraph.getText()\n",
        "\n",
        "          text_final = text_final.replace('\\\\', '')\n",
        "          locals()[\"df2\"+str(company_name)] = pd.DataFrame({\"Author\":[author], \"Date\":[date_final], \"Headline\":[headline], \"Text\":[text_final]})\n",
        "          locals()[\"df\"+str(company_name)] = locals()[\"df\"+str(company_name)].append(locals()[\"df2\"+str(company_name)])\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "      locals()[\"df\"+str(company_name)].to_csv(r'{0}.csv'.format(company_name))\n",
        "      files.download(\"{0}.csv\".format(company_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "company_name='Walt Disney'\n",
        "data = open('{0}.html'.format(company_name),'r')\n",
        "soup = BeautifulSoup(data, 'html.parser')\n",
        "data1 = soup.find('div', attrs = {'class': 'quote-page-article-listing'})\n",
        "links = []\n",
        "for link in data1.find_all('a'): \n",
        "  links.append(link.get('href'))\n",
        "\n",
        "links = list(dict.fromkeys(links))\n",
        "newlinks = [x for x in links if not x.startswith('https')]\n",
        "newlinks = [x for x in newlinks if not x.startswith('/earnings')]\n",
        "\n",
        "locals()[\"df\"+str(company_name)] = pd.DataFrame(columns = ['Author', 'Date', 'Headline', 'Text'])\n",
        "\n",
        "\n",
        "for link in newlinks: \n",
        "  try:\n",
        "    url = \"https://www.fool.com\" + link \n",
        "    html = request.urlopen(url).read().decode('utf8')\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    head = soup.find('section', attrs = {'class': 'usmf-new article-header'})\n",
        "    headline = head.find('h1').string\n",
        "    sub_headline = head.find('h2').string\n",
        "    author = soup.find('div', attrs = {'class': 'author-name'}).find('a').string\n",
        "    dates = soup.find_all('div', attrs = {'class': 'publication-date'})\n",
        "    dates_list = []\n",
        "    for date in dates: \n",
        "        dates_list.append(date.contents[2].strip())\n",
        "\n",
        "    for i in dates_list: \n",
        "        if i.startswith('Published') and len(dates_list) > 1: \n",
        "            date_final = i\n",
        "        else: \n",
        "            date_final = i \n",
        "\n",
        "    text = soup.find('span', attrs = {'class': 'article-content'})\n",
        "    paragraphs = text.find_all('p')\n",
        "    text_final = \"\"\n",
        "    for paragraph in paragraphs:\n",
        "        text_final = text_final + paragraph.getText()\n",
        "\n",
        "    text_final = text_final.replace('\\\\', '')\n",
        "    locals()[\"df2\"+str(company_name)] = pd.DataFrame({\"Author\":[author], \"Date\":[date_final], \"Headline\":[headline], \"Text\":[text_final]})\n",
        "    locals()[\"df\"+str(company_name)] = locals()[\"df\"+str(company_name)].append(locals()[\"df2\"+str(company_name)])\n",
        "\n",
        "  except:\n",
        "      pass\n",
        "  \n",
        "locals()[\"df\"+str(company_name)].to_csv(r'{0}.csv'.format(company_name))\n",
        "files.download(\"{0}.csv\".format(company_name))"
      ],
      "metadata": {
        "id": "nNpbQr74WWjV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5339bb09-4b70-431c-f3a1-d4461070ca8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6456c1c5-e1aa-4540-acda-81bfe164c8cf\", \"Walt Disney.csv\", 13524096)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Web Scraper - TMF.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}